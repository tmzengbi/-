## 中山大学计算机院本科生实验报告

#### **（2021 学年秋季学期）**

课程名称：高性能计算程序设计基础                   **批改人：**

| 实验  | **Lab6**                                          | 专业（方向） | **信息与计算科学** |
| ----- | ------------------------------------------------- | ------------ | ------------------ |
| 学号  | **18323004**                                      | 姓名         | **曾比**           |
| Email | **[2818097988@qq.com](mailto:2818097988@qq.com)** | 完成日期     |                    |

### 实验目的

1. 通过CUDA实现通用矩阵乘法（Lab1）的并行版本，CUDA Thread Block size从32增加至512，矩阵规模从512增加至8192。

2. 通过NVDIA的矩阵计算函数库CUBLAS计算矩阵相乘，矩阵规模从512增加至8192，并与任务1和任务2的矩阵乘法进行性能比较和分析，如果性能不如CUBLAS，思考并文字描述可能的改进方法

3. 问题描述：用直接卷积的方式对Input进行卷积，这里只需要实现2D, height*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3*3，步幅(stride)分别设置为1，2，3，可能需要通过填充(padding)配合步幅(stride)完成CNN操作。注：实验的卷积操作不需要考虑bias(b)，bias设置为0.

   输出：输出卷积结果以及计算时间

4. 输入：Input和Kernel (Filter)

   问题描述：用im2col的方式对Input进行卷积，这里只需要实现2D, height*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3*3。 注：实验的卷积操作不需要考虑bias(b)，bias设置为0，步幅(stride)分别设置为1，2，3。

   输出：卷积结果和时间。

5. 输入：Input和Kernel (Filter)

   问题描述：用im2col的方式对Input进行卷积，这里只需要实现2D, height*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3*3。 注：实验的卷积操作不需要考虑bias(b)，bias设置为0，步幅(stride)分别设置为1，2，3。

   输出：卷积结果和时间。

### 实验过程和核心代码

1. 通过CUDA实现通用矩阵乘法（Lab1）的并行版本，CUDA Thread Block size从32增加至512，矩阵规模从512增加至8192。

在写代码前，首先写随机数据生成器。

```c
#include <stdlib.h>
#include <time.h>
#include <stdio.h>
int main(int argc, char *argv[]) {
    srand(time(NULL));
    if(argc != 2) {
        printf("matrix size N (N X N) needed\n");
        exit(-1);
    }
    int N = strtol(argv[1], NULL, 10);
    int M = N, K = N;
    FILE *fp;
    if((fp = fopen("a.in", "w")) == NULL) {
        perror("cannot open file");
        exit(-1);
    }
    fwrite(&N, sizeof(int), 1, fp);
    fwrite(&M, sizeof(int), 1, fp);
    fwrite(&K, sizeof(int), 1, fp);
    for(int i = 0; i < N * M; ++ i) {
        float x = rand() % 5 + 1;
        fwrite(&x, sizeof(float), 1, fp);
    }
    for(int i = 0; i < M * K; ++ i) {
        float x = rand() % 5 + 1;
        fwrite(&x, sizeof(float), 1, fp);
    }
}
```

​	和前面的 `lab` 不一样的地方是这里的数据不是使用 python 而是 c 而且使用二进制存储。因为在实际操作中，发现 python 在造大数据的时候，耗时特别长，而且对于普通文件读写，IO 占用了大量的时间，使用二进制文件读写可以大大减少 IO 时间。

- 读取数据

```c++
if((fp = fopen("a.in", "r")) == NULL) {
    perror("cannot open file");
    exit(-1);
}
fread(&N, 1, sizeof(int), fp);
fread(&M, 1, sizeof(int), fp);
fread(&K, 1, sizeof(int), fp);
A = (float*) malloc (sizeof(float) * N * M);
B = (float*) malloc (sizeof(float) * M * K);
C = (float*) malloc (sizeof(float) * N * K);
fread(A, sizeof(float), N * M, fp);
fread(B, sizeof(float), M * K, fp);
```

- 为 device 中的变量分配空间，将本地的数据复制到 device 上去。

```c++
float *d_A, *d_B, *d_C;
cudaMalloc((void**) &d_A, sizeof(float) * N * M);
cudaMalloc((void**) &d_B, sizeof(float) * M * K);
cudaMalloc((void**) &d_C, sizeof(float) * N * K);

cudaMemcpy(d_A, A, sizeof(float) * N * M, cudaMemcpyHostToDevice);
cudaMemcpy(d_B, B, sizeof(float) * M * K, cudaMemcpyHostToDevice);
cudaMemset(d_C, 0, sizeof(float) * N * K);
```

- 提供计时方式（其中 solve 函数是后面会提到的计算核心代码）

```c++
cudaEvent_t e_start, e_stop;
cudaEventCreate(&e_start);
cudaEventCreate(&e_stop);

cudaEventRecord(e_start, 0);
solve<<<N / THREADS_PER_BLOCK + 1 ,THREADS_PER_BLOCK>>>(d_A, d_B, d_C, N, M, K);
cudaEventRecord(e_stop, 0);

cudaEventSynchronize(e_stop);
float elapsedtime;
cudaEventElapsedTime(&elapsedtime, e_start, e_stop);
printf("finish calculating, costing %f\n", elapsedtime);
```

- 计算核心代码

```c++
__global__ void solve(float *A, float *B, float *C, int N, int M, int K) {
    #define idA (i * M + k) 
    #define idB (k * K + j)
    #define idC (i * K + j)

    int threadId = blockIdx.x * blockDim.x + threadIdx.x;
    int i = threadId;
    if(i >= N) return;
    for(int k = 0; k < M; ++ k) {
        float tmp = A[idA];
        for(int j = 0; j < K; ++ j)
            C[idC] += tmp * B[idB];
    }
    #undef idA
    #undef idB
    #undef idC
}
```

- 将 device 上得到的结果复制到 local 上来

```c++
cudaMemcpy(C, d_C, sizeof(float) * N * K,cudaMemcpyDeviceToHost);
```

- 收尾工作（输出可能存在的错误，并回收分配出去的内存）

```c++
cudaError_t err = cudaGetLastError();
printf("%s\n",cudaGetErrorString(err));
cudaFree(d_A);
cudaFree(d_B);
cudaFree(d_C);
free(A);
free(B);
free(C);
```



2. 通过NVDIA的矩阵计算函数库CUBLAS计算矩阵相乘，矩阵规模从512增加至8192，并与任务1和任务2的矩阵乘法进行性能比较和分析，如果性能不如CUBLAS，思考并文字描述可能的改进方法

代码和实验 1 大同小异，只是需要修改核心计算函数

```c++
cublasHandle_t handle;
cublasCreate(&handle);
cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, K, M, N, &alpha, d_B, K, d_A, N, &beta, d_C, K);
cublasDestroy(handle);
```

​	这里不容易理解的地方就是计算过程中，cuda 为了兼容 Fortran，采用的是列优先而不是我们习惯的行优先存储的方式在存储矩阵。因此计算的过程中，实际上计算的是 $B^TA^T$，最终得到的结果是 $(AB)^T$ 也就是顺序存储的 $AB$ 



3. 问题描述：用直接卷积的方式对Input进行卷积，这里只需要实现2D, height*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3*3，步幅(stride)分别设置为1，2，3，可能需要通过填充(padding)配合步幅(stride)完成CNN操作。注：实验的卷积操作不需要考虑bias(b)，bias设置为0.

   输出：输出卷积结果以及计算时间

这个问题中，需要重新设计随机矩阵生成器。

```c++
#include <stdlib.h>
#include <time.h>
#include <stdio.h>
int main(int argc, char *argv[]) {
    srand(time(NULL));
    if(argc != 3) {
        printf("Input size N * N and Kernel size M * M needed\n");
        exit(-1);
    }
    int N = strtol(argv[1], NULL, 10);
    int M = strtol(argv[2], NULL, 10);
    FILE *fp;
    if((fp = fopen("a.in", "w")) == NULL) {
        perror("cannot open file");
        exit(-1);
    }
    fwrite(&N, sizeof(int), 1, fp);
    fwrite(&M, sizeof(int), 1, fp);
    for(int i = 0; i < N * N; ++ i) {
        float x = rand() % 5 + 1;
        fwrite(&x, sizeof(float), 1, fp);
    }
    for(int i = 0; i < M * M; ++ i) {
        float x = rand() % 5 + 1;
        fwrite(&x, sizeof(float), 1, fp);
    }
}
```

这个实验中，其他代码于前面的实验大同小异。计算过程中很大的不同就是使用了二维方式来维护线程。

```c++
#define THREADS_PER_BLOCK 32
dim3 block((K + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, (K + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK);
dim3 threads(THREADS_PER_BLOCK, THREADS_PER_BLOCK);
cudacnn<<<block, threads>>>(d_input, d_kernel, d_output, N, M, K);
```

- 实验主体

```c++
__global__ void cudacnn(float *input, float *kernel, float *out, int N, int M, int K) {
    int threadId_x = blockIdx.x * blockDim.x + threadIdx.x;
    int threadId_y = blockIdx.y * blockDim.y + threadIdx.y;
    if(threadId_x >= K || threadId_y >= K)
        return;
    // printf("%d %d\n", threadId_x, threadId_y);
    int x = threadId_x * stride, y = threadId_y * stride;
    float sum = 0;
    for(int i = 0; i < M ; ++ i) 
        for(int j = 0; j < M ; ++ j) {
            if(x + i < N && y + j < N) 
                sum += input[(x + i) * N + (y + j)] * kernel[i * M + j];
        }
    out[threadId_x * K + threadId_y] = sum;
}   
```

​	其中 `threadId_x` 和 `threadId_y` 是对应的横坐标和纵坐标。



### 实验结果

实验一：

变化矩阵规模和 BLOCK SIZE 时，计算花费时间如下。

首先测试计算正确性

<img src="D:\课件\大三\高性能计算\lab\lab6\pic\1.png" alt="1" style="zoom:67%;" />

| 矩阵规模 \\ BLOCK SIZE | 32          | 64          | 128         | 256         | 512          |
| ---------------------- | ----------- | ----------- | ----------- | ----------- | ------------ |
| 512                    | 41.010178   | 47.328255   | 75.029503   | 137.303040  | 239.241211   |
| 1024                   | 138.493958  | 161.446915  | 253.981689  | 508.704773  | 958.390259   |
| 2048                   | 688.211975  | 786.183167  | 1190.199341 | 2045.064209 | 3865.294922  |
| 4096                   | 4111.473633 | 4086.002686 | 4943.251465 | 8232.208008 | 15527.419922 |

计算花费时间随着矩阵规模变大而增大，随着 BLOCK SIZE 增大而增大。



实验二：

验证正确性：

<img src="D:\课件\大三\高性能计算\lab\lab6\pic\2.png" alt="2" style="zoom:67%;" />

变化矩阵规模时，计算花费时间如下。

| 256        | 512        | 1024       | 2048       | 4096       | 8192       |
| ---------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| 223.700287 | 242.601471 | 246.827744 | 236.653412 | 231.686584 | 330.544556 |

可以看到每个矩阵计算时间都差不多，



实验三：

首先验算正确性：

<img src="D:\课件\大三\高性能计算\lab\lab6\pic\3.png" alt="3" style="zoom:67%;" />

变化 input size 和 kernel size 时候，计算花费时间如下。

| Input size \\ kernel size | 32        | 64         | 128        | 256         |
| ------------------------- | --------- | ---------- | ---------- | ----------- |
| 256                       | 0.858112  | 3.368960   | 13.381632  | 2.028224    |
| 512                       | 2.548736  | 13.362176  | 26.750977  | 53.630241   |
| 1024                      | 9.256960  | 33.971199  | 114.930687 | 361.771423  |
| 2048                      | 35.534847 | 159.796219 | 533.632019 | 1812.117554 |



### 实验感想 

​	实验实际上花费了大量时间，首先是 cuda 编程的不熟悉，不了解其报错机制，中间出现了问题都不了解，最后是直接在所有程序都加上了以下两句话。

```c++
cudaError_t err = cudaGetLastError();
printf("%s\n",cudaGetErrorString(err));
```

如果结果是 

```
no error
```

那么表示没有错误



